{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19863\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "lag = 12\n",
    "config = {\"batch\": 256, \"epochs\": 600}\n",
    "file1 = 'train.csv'\n",
    "file2 = 'test.csv'\n",
    "X_train, y_train, _, _, _ = process_data(file1, file2, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the data\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "def process_data(train, test, lags):\n",
    "    \"\"\"Process data\n",
    "    Reshape and split train\\test data.\n",
    "\n",
    "    # Arguments\n",
    "        train: String, name of .csv train file.\n",
    "        test: String, name of .csv test file.\n",
    "        lags: integer, time lag.\n",
    "    # Returns\n",
    "        X_train: ndarray.\n",
    "        y_train: ndarray.\n",
    "        X_test: ndarray.\n",
    "        y_test: ndarray.\n",
    "        scaler: StandardScaler.\n",
    "    \"\"\"\n",
    "    attr = 'Lane 1 Flow (Veh/5 Minutes)'\n",
    "    df1 = pd.read_csv(train, encoding='utf-8').fillna(0)\n",
    "    df2 = pd.read_csv(test, encoding='utf-8').fillna(0)\n",
    "\n",
    "    # scaler = StandardScaler().fit(df1[attr].values)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(df1[attr].values.reshape(-1, 1))\n",
    "#     .reshape(1, -1)[0]\n",
    "    flow1 = scaler.transform(df1[attr].values.reshape(-1, 1))\n",
    "    flow2 = scaler.transform(df2[attr].values.reshape(-1, 1))\n",
    "\n",
    "    train, test = [], []\n",
    "    for i in range(lags, len(flow1)):\n",
    "        train.append(flow1[i - lags: i + 1])\n",
    "    for i in range(lags, len(flow2)):\n",
    "        test.append(flow2[i - lags: i + 1])\n",
    "\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "#     np.random.shuffle(train)\n",
    "\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    X_test = test[:, :-1]\n",
    "    y_test = test[:, -1]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19863\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "lag = 12\n",
    "config = {\"batch\": 256, \"epochs\": 600}\n",
    "file1 = 'train.csv'\n",
    "file2 = 'test.csv'\n",
    "X_train, y_train, _, _, _ = process_data(file1, file2, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06091371  0.06598985  0.05583756  0.06598985  0.05076142  0.05076142\n",
      "  0.06598985  0.05583756  0.05076142  0.03045685  0.03553299  0.04060914]\n",
      "[ 0.06598985  0.05583756  0.06598985  0.05076142  0.05076142  0.06598985\n",
      "  0.05583756  0.05076142  0.03045685  0.03553299  0.04060914  0.04060914]\n",
      "[ 0.05583756  0.06598985  0.05076142  0.05076142  0.06598985  0.05583756\n",
      "  0.05076142  0.03045685  0.03553299  0.04060914  0.04060914  0.06091371]\n",
      "[ 0.06598985  0.05076142  0.05076142  0.06598985  0.05583756  0.05076142\n",
      "  0.03045685  0.03553299  0.04060914  0.04060914  0.06091371  0.03553299]\n",
      "[ 0.05076142  0.05076142  0.06598985  0.05583756  0.05076142  0.03045685\n",
      "  0.03553299  0.04060914  0.04060914  0.06091371  0.03553299  0.02538071]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.41624365  0.40101523  0.40101523  0.40101523  0.44162437  0.40609137\n",
      "  0.40101523  0.3857868   0.32994924  0.42639594  0.30456853  0.31979695]\n",
      "[ 0.03045685  0.03553299  0.01522843  0.01015228  0.01522843  0.00507614\n",
      "  0.02030457  0.03045685  0.02030457  0.03553299  0.03553299  0.03553299]\n",
      "[ 0.05583756  0.05583756  0.06598985  0.05583756  0.03553299  0.04568528\n",
      "  0.05583756  0.03553299  0.03045685  0.04568528  0.03553299  0.02538071]\n",
      "[ 0.54822335  0.52284264  0.52284264  0.58375635  0.54822335  0.50253807\n",
      "  0.54314721  0.52284264  0.43654822  0.48730964  0.56852792  0.54822335]\n",
      "[ 0.03045685  0.03045685  0.04060914  0.01522843  0.05076142  0.08629442\n",
      "  0.08629442  0.05076142  0.05583756  0.07106599  0.08121827  0.16751269]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06091371]\n",
      " [ 0.06598985]\n",
      " [ 0.05583756]\n",
      " [ 0.06598985]\n",
      " [ 0.05076142]\n",
      " [ 0.05076142]\n",
      " [ 0.06598985]\n",
      " [ 0.05583756]\n",
      " [ 0.05076142]\n",
      " [ 0.03045685]\n",
      " [ 0.03553299]\n",
      " [ 0.04060914]]\n",
      "[[ 0.06598985]\n",
      " [ 0.05583756]\n",
      " [ 0.06598985]\n",
      " [ 0.05076142]\n",
      " [ 0.05076142]\n",
      " [ 0.06598985]\n",
      " [ 0.05583756]\n",
      " [ 0.05076142]\n",
      " [ 0.03045685]\n",
      " [ 0.03553299]\n",
      " [ 0.04060914]\n",
      " [ 0.04060914]]\n",
      "[[ 0.05583756]\n",
      " [ 0.06598985]\n",
      " [ 0.05076142]\n",
      " [ 0.05076142]\n",
      " [ 0.06598985]\n",
      " [ 0.05583756]\n",
      " [ 0.05076142]\n",
      " [ 0.03045685]\n",
      " [ 0.03553299]\n",
      " [ 0.04060914]\n",
      " [ 0.04060914]\n",
      " [ 0.06091371]]\n",
      "[[ 0.06598985]\n",
      " [ 0.05076142]\n",
      " [ 0.05076142]\n",
      " [ 0.06598985]\n",
      " [ 0.05583756]\n",
      " [ 0.05076142]\n",
      " [ 0.03045685]\n",
      " [ 0.03553299]\n",
      " [ 0.04060914]\n",
      " [ 0.04060914]\n",
      " [ 0.06091371]\n",
      " [ 0.03553299]]\n",
      "[[ 0.05076142]\n",
      " [ 0.05076142]\n",
      " [ 0.06598985]\n",
      " [ 0.05583756]\n",
      " [ 0.05076142]\n",
      " [ 0.03045685]\n",
      " [ 0.03553299]\n",
      " [ 0.04060914]\n",
      " [ 0.04060914]\n",
      " [ 0.06091371]\n",
      " [ 0.03553299]\n",
      " [ 0.02538071]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Traffic Flow Prediction with Neural Networks(SAEs、LSTM、GRU).\n",
    "\"\"\"\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data.data import process_data\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_results(y_true, y_preds, names):\n",
    "    \"\"\"Plot\n",
    "    Plot the true data and predicted data.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "        names: List, Method names.\n",
    "    \"\"\"\n",
    "    d = '2016-3-4 00:00'\n",
    "    x = pd.date_range(d, periods=288, freq='5min')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.plot(x, y_true, label='True Data')\n",
    "    for name, y_pred in zip(names, y_preds):\n",
    "        ax.plot(x, y_pred, label=name)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time of Day')\n",
    "    plt.ylabel('Flow')\n",
    "\n",
    "    date_format = mpl.dates.DateFormatter(\"%H:%M\")\n",
    "    ax.xaxis.set_major_formatter(date_format)\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    lstm = load_model('model/lstm.h5')\n",
    "    gru = load_model('model/gru.h5')\n",
    "    saes = load_model('model/saes.h5')\n",
    "    models = [lstm, gru, saes]\n",
    "    names = ['LSTM', 'GRU', 'SAEs']\n",
    "\n",
    "    lag = 12\n",
    "    file1 = 'data/train.csv'\n",
    "    file2 = 'data/test.csv'\n",
    "    _, _, X_test, y_test, scaler = process_data(file1, file2, lag)\n",
    "    y_test = scaler.inverse_transform(y_test.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "\n",
    "    y_preds = []\n",
    "    for name, model in zip(names, models):\n",
    "        if name == 'SAEs':\n",
    "            X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1]))\n",
    "        else:\n",
    "            X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "        file = 'images/' + name + '.png'\n",
    "        plot_model(model, to_file=file, show_shapes=True)\n",
    "        predicted = model.predict(X_test)\n",
    "        predicted = scaler.inverse_transform(predicted.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "        y_preds.append(predicted[:288])\n",
    "        print(name)\n",
    "        eva_regress(y_test, predicted)\n",
    "\n",
    "    plot_results(y_test[: 288], y_preds, names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
