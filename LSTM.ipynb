{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findTime(x):\n",
    "    return x.time()\n",
    "def findDate(x):\n",
    "    return x.date()\n",
    "\n",
    "\n",
    "filelist = os.listdir('measurement')\n",
    "filelist.sort()\n",
    "startpoint = np.where(np.array(filelist) == '16157')[0][0]\n",
    "filelist = filelist[startpoint:]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for fileid in filelist:\n",
    "    data = pd.read_csv('measurement/'+fileid+'/tab_ldt.csv')\n",
    "    df = pd.concat([df,data])\n",
    "\n",
    "\n",
    "for roadid in df['DEVICEID'].unique(): # 对测试路段循环\n",
    "    road_data = df[df['DEVICEID'] == roadid].copy()\n",
    "    road_data['FROMTIME'] = pd.to_datetime(road_data['FROMTIME'])\n",
    "    road_data.index = road_data['FROMTIME']\n",
    "    road_data['FROMTIME-Time'] = road_data['FROMTIME'].apply(findTime)  # 找到时间\n",
    "    road_data['FROMTIME-Date'] = road_data['FROMTIME'].apply(findDate)  # 找到日期\n",
    "    road_data.to_csv('train_data/data/'+'%s.csv'%roadid)\n",
    "    # 对每个日期进行绘图\n",
    "    plt.figure(figsize= (20,5))\n",
    "    plt.title(str(roadid))\n",
    "    for date in road_data['FROMTIME-Date'].unique():\n",
    "        df_temp = road_data[road_data['FROMTIME-Date'] == date]\n",
    "        data3 = df_temp.resample(datetime.timedelta(seconds=5 * 60)).sum()\n",
    "        data3.index = pd.Series(data3.index).apply(findTime)\n",
    "        plt.plot(data3.index,data3['FLOW'],label=date)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "road_data = pd.read_csv('train_data/data/5696.csv')\n",
    "road_data['FROMTIME'] = pd.to_datetime(road_data['FROMTIME'])\n",
    "road_data.index = road_data['FROMTIME']\n",
    "road_data['FROMTIME-Time'] = road_data['FROMTIME'].apply(findTime)  # 找到时间\n",
    "road_data['FROMTIME-Date'] = road_data['FROMTIME'].apply(findDate)  # 找到日期\n",
    "road_data\n",
    "# 对每个日期进行绘图\n",
    "plt.figure(figsize= (20,5))\n",
    "plt.title(str(5696))\n",
    "for date in road_data['FROMTIME-Date'].unique():\n",
    "    df_temp = road_data[road_data['FROMTIME-Date'] == date]\n",
    "    data3 = df_temp.resample(datetime.timedelta(seconds=5 * 60)).sum()\n",
    "    data3.index = pd.Series(data3.index).apply(findTime)\n",
    "    plt.plot(data3.index,data3['FLOW'],label=date)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取文件\n",
    "xianquan = road_data.resample(datetime.timedelta(seconds=5 * 60)).sum()\n",
    "df = xianquan.copy()\n",
    "# 打印头部\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#筛选出题目要求的7点到22点的数据\n",
    "df['FROMTIME'] = pd.to_datetime(df.index)\n",
    "df['FROMTIME-Time'] = df[\"FROMTIME\"].apply(findTime)  # 找到时间\n",
    "df['FROMTIME-Date'] = df[\"FROMTIME\"].apply(findDate)  # 找到日期\n",
    "df=df[(pd.to_datetime(df[\"FROMTIME-Time\"],format = '%H:%M:%S')>= pd.to_datetime('07:00:00',format = '%H:%M:%S'))&(pd.to_datetime(df[\"FROMTIME-Time\"],format = '%H:%M:%S')<= pd.to_datetime('22:00:00',format = '%H:%M:%S'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练集：2019年7月周六周日7月6日，7日；13日，14日；20日，21日；27日，28日；其余天数为工作日\n",
    "#待预测的天数：8月3日，8月4日为周六周日，其余为工作日\n",
    "weekend_list=[\"2019-07-06\",\"2019-07-07\",\"2019-07-13\",\"2019-07-14\",\"2019-07-20\",\"2019-07-21\",\"2019-07-27\",\"2019-07-28\"]\n",
    "\n",
    "df_weekend=pd.DataFrame()\n",
    "for day in weekend_list:\n",
    "    temp=df[pd.to_datetime(df['FROMTIME-Date'],format = '%Y-%m-%d')==pd.to_datetime(day,format = '%Y-%m-%d')]\n",
    "    df_weekend=pd.concat([df_weekend,temp])\n",
    "    #df_weekend包括所有的周末数据\n",
    "df_weekend.index = df_weekend['FROMTIME']\n",
    "df_weekend.to_csv('train_data/lstm/weekend_5696')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weekday_list=[\"2019-07-01\",\"2019-07-02\",\"2019-07-03\",\"2019-07-04\",\"2019-07-05\",\"2019-07-08\",\"2019-07-09\",\"2019-07-10\",\n",
    "             \"2019-07-11\",\"2019-07-12\",\"2019-07-15\",\"2019-07-16\",\"2019-07-17\",\"2019-07-18\",\"2019-07-19\",\"2019-07-22\",\n",
    "             \"2019-07-23\",\"2019-07-24\",\"2019-07-25\",\"2019-07-26\",\"2019-07-29\",\"2019-07-30\",\"2019-07-31\"]\n",
    "df_weekday=pd.DataFrame()\n",
    "for day in weekday_list:\n",
    "    temp=df[pd.to_datetime(df['FROMTIME-Date'],format = '%Y-%m-%d')==pd.to_datetime(day,format = '%Y-%m-%d')]\n",
    "    df_weekday=pd.concat([df_weekday,temp])\n",
    "    #df_weekday包括所有的工作日数据\n",
    "\n",
    "df_weekday.index = df_weekday['FROMTIME']\n",
    "df_weekday.to_csv('train_data/lstm/weekday_5696')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (20,5))\n",
    "plt.title(str('5696'))\n",
    "plt.plot(df_weekend.index,df_weekend['COUNT'])\n",
    "plt.plot(df_weekday.index,df_weekday['COUNT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#对数据进行处理\n",
    "def process_data(train, test, lags):\n",
    "    \"\"\"Process data\n",
    "    Reshape and split train\\test data.\n",
    "\n",
    "    # Arguments\n",
    "        train: String, name of .csv train file.\n",
    "        test: String, name of .csv test file.\n",
    "        lags: integer, time lag.\n",
    "    # Returns\n",
    "        X_train: ndarray.\n",
    "        y_train: ndarray.\n",
    "        X_test: ndarray.\n",
    "        y_test: ndarray.\n",
    "        scaler: StandardScaler.\n",
    "    \"\"\"\n",
    "    attr = 'COUNT'\n",
    "    df1 = pd.read_csv(train, encoding='utf-8').fillna(0)\n",
    "    df2 = pd.read_csv(test, encoding='utf-8').fillna(0)\n",
    "\n",
    "    # scaler = StandardScaler().fit(df1[attr].values)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(df1[attr].values.reshape(-1, 1))\n",
    "    flow1 = scaler.transform(df1[attr].values.reshape(-1, 1))\n",
    "    flow2 = scaler.transform(df2[attr].values.reshape(-1, 1))\n",
    "\n",
    "    train, test = [], []\n",
    "    #关于train和test的划分要清楚\n",
    "    #这里是将最后一周的数据作为测试集\n",
    "#     for i in range(lags, len(flow1)):\n",
    "#         train.append(flow1[i - lags: i + 1])\n",
    "#     for i in range(lags, len(flow2)):\n",
    "#         test.append(flow2[i - lags: i + 1])\n",
    "\n",
    "    #训练集划分的时候注意是每天7点开始，22点结束，不能用22点预测7点的，一天一共16个小时\n",
    "    for i in range(lags, len(flow1),12):\n",
    "        if (i/12)%16==0:\n",
    "            pass\n",
    "        else:\n",
    "            #0:i+1实际输出的长度是i,比如i=12时,输出的是flow[0]...flow[12]。所以是输出了13个数据\n",
    "            temp=flow1[i - lags: i + 12]\n",
    "            if len(temp)==24:\n",
    "                train.append(temp)\n",
    "                \n",
    "    for i in range(lags, len(flow2),12):\n",
    "        if (i/12)%16==0:\n",
    "            pass\n",
    "        else:\n",
    "            temp=flow1[i - lags: i + 12]\n",
    "            if len(temp)==24:\n",
    "                test.append(temp)\n",
    "\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    np.random.shuffle(train)\n",
    "    #train[:,-1] train这个二维的数据，逗号分隔开的前面的\":\"是说取全部的行，逗号后面的-1是说取最后一列。\n",
    "    #train[:, :-1]是指除去数据的最后一列剩下的数据\n",
    "    X_train = train[:,0:12]\n",
    "    y_train = train[:,-12:]\n",
    "    X_test = test[:,0:12]\n",
    "    y_test = test[:,-12:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, scaler\n",
    "\n",
    "\n",
    "#对数据进行处理\n",
    "def process_data2(train, test, lags):\n",
    "    attr = 'COUNT'\n",
    "    df1 = pd.read_csv(train, encoding='utf-8').fillna(0)\n",
    "    df2 = pd.read_csv(test, encoding='utf-8').fillna(0)\n",
    "\n",
    "    # scaler = StandardScaler().fit(df1[attr].values)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(df1[attr].values.reshape(-1, 1))\n",
    "    flow1 = scaler.transform(df1[attr].values.reshape(-1, 1))\n",
    "    flow2 = scaler.transform(df2[attr].values.reshape(-1, 1))\n",
    "\n",
    "    train, test = [], []\n",
    "    #关于train和test的划分要清楚\n",
    "    #这里是将最后一周的数据作为测试集\n",
    "    for i in range(lags, len(flow1)):\n",
    "        train.append(flow1[i - lags: i + 1])\n",
    "    for i in range(lags, len(flow2)):\n",
    "        test.append(flow2[i - lags: i + 1])\n",
    "\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    np.random.shuffle(train)\n",
    "    #train[:,-1] train这个二维的数据，逗号分隔开的前面的\":\"是说取全部的行，逗号后面的-1是说取最后一列。\n",
    "    #train[:, :-1]是指除去数据的最后一列剩下的数据\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:,-1] \n",
    "    X_test = test[:, :-1]\n",
    "    y_test = test[:,-1]\n",
    "\n",
    "    return  X_train, y_train, X_test, y_test, scaler,train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义LSTM模型\n",
    "def get_lstm(units):\n",
    "    \"\"\"LSTM(Long Short-Term Memory)\n",
    "    Build LSTM Model.\n",
    "\n",
    "    # Arguments\n",
    "        units: List(int), number of input, output and hidden units.\n",
    "    # Returns\n",
    "        model: Model, nn model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units[1], input_shape=(units[0], 1), return_sequences=True))\n",
    "    model.add(LSTM(units[2]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=units[3],activation='linear'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "训练，LSTM、GRU按照正常的RNN网络进行训练。使用train_model()函数训练。\n",
    "\n",
    "使用RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)作为优化器，batch_szie为256，lags为12(即时滞长度为一个小时)。\n",
    "\"\"\"\n",
    "def train_model(model, X_train, y_train, name, config):\n",
    "    \"\"\"train\n",
    "    train a single model.\n",
    "\n",
    "    # Arguments\n",
    "        model: Model, NN model to train.\n",
    "        X_train: ndarray(number, lags), Input data for train.\n",
    "        y_train: ndarray(number, ), result data for train.\n",
    "        name: String, name of model.\n",
    "        config: Dict, parameter for train.\n",
    "    \"\"\"\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mape'])\n",
    "    # early = EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "    hist = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=config[\"batch\"],\n",
    "        epochs=config[\"epochs\"],\n",
    "        validation_split=0.15)#原先的参数是0.05\n",
    "\n",
    "    model.save('train_data/model/' + name + '.h5')\n",
    "    df = pd.DataFrame.from_dict(hist.history)\n",
    "    df.to_csv('train_data/model/' + name + ' loss.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Percentage Error\n",
    "    Calculate the mape.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "    # Returns\n",
    "        mape: Double, result data for train.\n",
    "    \"\"\"\n",
    "\n",
    "    y = [x for x in y_true if x > 0]\n",
    "    y_pred = [y_pred[i] for i in range(len(y_true)) if y_true[i] > 0]\n",
    "\n",
    "    num = len(y_pred)\n",
    "    sums = 0\n",
    "\n",
    "    for i in range(num):\n",
    "        tmp = abs(y[i] - y_pred[i]) / y[i]\n",
    "        sums += tmp\n",
    "    if num!=0:\n",
    "        mape = sums * (100 / num)\n",
    "    else:\n",
    "        mape=0\n",
    "    return mape\n",
    "\n",
    "\n",
    "def eva_regress(y_true, y_pred):\n",
    "    \"\"\"Evaluation\n",
    "    evaluate the predicted resul.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "    \"\"\"\n",
    "\n",
    "    mape = MAPE(y_true, y_pred)\n",
    "    vs = metrics.explained_variance_score(y_true, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    print('explained_variance_score:%f' % vs)\n",
    "    print('mape:%f%%' % mape)\n",
    "    print('mae:%f' % mae)\n",
    "    print('mse:%f' % mse)\n",
    "    print('rmse:%f' % math.sqrt(mse))\n",
    "    print('r2:%f' % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#周末数据的训练\n",
    "df_weekend=pd.read_csv('train_data/lstm/weekend_5696')\n",
    "df_weekday=pd.read_csv('train_data/lstm/weekday_5696')\n",
    "data1=df_weekend[(pd.to_datetime(df_weekend.index,format = '%Y-%m-%d %H:%M:%S')<= pd.to_datetime('2019-07-26 22:00:00',format = '%Y-%m-%d %H:%M:%S'))]\n",
    "data2=df_weekend[(pd.to_datetime(df_weekend.index,format = '%Y-%m-%d %H:%M:%S')> pd.to_datetime('2019-07-26 22:00:00',format = '%Y-%m-%d %H:%M:%S'))]\n",
    "data1.to_csv('train_data/train.csv')\n",
    "data2.to_csv('train_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#数据处理\n",
    "lag = 12\n",
    "file1 = 'train_data/train.csv'\n",
    "file2 = 'train_data/test.csv'\n",
    "\n",
    "X_train, y_train, X_test, y_test, scaler= process_data(file1, file2, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=y_train.reshape(y_train.shape[0],y_train.shape[1])\n",
    "y_test=y_test.reshape(y_test.shape[0],y_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练模型\n",
    "units=[X_train.shape[1],50,50,y_train.shape[1]]\n",
    "model=get_lstm(units)\n",
    "name='lstm'\n",
    "config={\"batch\":100,\"epochs\":10000}\n",
    "train_model(model, X_train, y_train, name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = load_model('train_data/model/lstm.h5')\n",
    "\n",
    "model=lstm\n",
    "name='LSTM'\n",
    "\n",
    "lag = 12\n",
    "file1 = 'train_data/train.csv'\n",
    "file2 = 'train_data/test.csv'\n",
    "_, _, X_test, y_test, scaler = process_data(file1, file2, lag)\n",
    "y_test=y_test.reshape(y_test.shape[0],y_test.shape[1])\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "y_preds = []\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "file = 'train_data/model' + name + '.png'\n",
    "plot_model(model, to_file=file, show_shapes=True)\n",
    "predicted = model.predict(X_test)\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "# y_preds.append(predicted)#[:12]\n",
    "y_preds=predicted\n",
    "print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_test)):\n",
    "    plt.figure()\n",
    "    plt.plot(y_test[i])\n",
    "    plt.plot(y_preds[i])\n",
    "    eva_regress(y_test[i], y_preds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 工作日"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#工作日的数据进行训练，前15天训练集，后5天测试集\n",
    "df_weekday=pd.read_csv('train_data/lstm/weekday_5696')\n",
    "df_weekday.index=df_weekday[\"FROMTIME\"]\n",
    "data5=df_weekday[(pd.to_datetime(df_weekday.index,format = '%Y-%m-%d %H:%M:%S')<= pd.to_datetime('2019-07-24 22:00:00',format = '%Y-%m-%d %H:%M:%S'))]\n",
    "data6=df_weekday[(pd.to_datetime(df_weekday.index,format = '%Y-%m-%d %H:%M:%S')> pd.to_datetime('2019-07-24 22:00:00',format = '%Y-%m-%d %H:%M:%S'))]\n",
    "data5.to_csv('train_data/train_5696_wd.csv')\n",
    "data6.to_csv('train_data/test_5696_wd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#数据处理\n",
    "lag = 12\n",
    "file1 = 'train_data/train_5696_wd.csv'\n",
    "file2 = 'train_data/test_5696_wd.csv'\n",
    "\n",
    "X_train, y_train, X_test, y_test, scaler= process_data(file1, file2, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=y_train.reshape(y_train.shape[0],y_train.shape[1])\n",
    "y_test=y_test.reshape(y_test.shape[0],y_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练模型\n",
    "units=[X_train.shape[1],50,50,y_train.shape[1]]\n",
    "model=get_lstm(units)\n",
    "name='lstm'\n",
    "config={\"batch\":100,\"epochs\":10000}\n",
    "train_model(model, X_train, y_train, name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = load_model('train_data/model/lstm.h5')\n",
    "\n",
    "model=lstm\n",
    "name='LSTM'\n",
    "\n",
    "lag = 12\n",
    "file1 = 'train_data/train_5696_wd.csv'\n",
    "file2 = 'train_data/test_5696_wd.csv'\n",
    "_, _, X_test, y_test, scaler = process_data(file1, file2, lag)\n",
    "y_test=y_test.reshape(y_test.shape[0],y_test.shape[1])\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "y_preds = []\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "file = 'train_data/model' + name + '.png'\n",
    "plot_model(model, to_file=file, show_shapes=True)\n",
    "predicted = model.predict(X_test)\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "# y_preds.append(predicted)#[:12]\n",
    "y_preds=predicted\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_test)):\n",
    "    plt.figure()\n",
    "    plt.plot(y_test[i])\n",
    "    plt.plot(y_preds[i])\n",
    "    eva_regress(y_test[i], y_preds[i])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
